{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiFG5vFZQDZl"
      },
      "source": [
        "Code adapted from Youtube user @aniquemaniac. The `.ipynb` is optimized on Google Colab. The original pipeline is used to train Tesseract 4.1 on customed English font family, not Japanese handwriting. Thus, I made several modifications to make the pipeline work for this purpose.\n",
        "\n",
        "Download these required files from github and upload to Google Drive\n",
        "\n",
        "**1. Tesseract 4.1**\n",
        "\n",
        "\n",
        "https://github.com/tesseract-ocr/tesseract/tree/4.1\n",
        "\n",
        "**2. Download jpn.traineddata**\n",
        "\n",
        "https://github.com/tesseract-ocr/tessdata_best\n",
        "\n",
        "After downloading it, put `jpn.traineddata` inside the downloaded tesseract folder `tesseract/tessdata`\n",
        "\n",
        "**3. Langdata lstm**\n",
        "\n",
        "https://github.com/tesseract-ocr/langdata_lstm\n",
        "\n",
        "Download only some important directory.\n",
        "So download this chrome extension extension. This will allow you to select and download specific directory and files. https://chrome.google.com/webstore/detail/gitzip-for-github/ffabmkklhbepgcgfonabamgnfafbdlkn\n",
        "\n",
        "\n",
        "Watch this video to locate where to put the files in the `langdata_lstm` folder: https://www.youtube.com/watch?v=V2chutR7RZo\n",
        "\n",
        "1. Specific language Code folder, `jpn`, `chi_sim`, `chi_tra`\n",
        "2. `Licence`\n",
        "3. `desired_bigrams.txt`\n",
        "4. `font_properties`\n",
        "5. `radical-stroke.txt`\n",
        "6. `forbidden_characters_default`\n",
        "7. `Katakana.unicharset`, `Katakana.xheights`, `Hiragana.unicharset`, `Hiragana.xheights`\n",
        "\n",
        "Folder Structure ▶\n",
        "\n",
        "    ------tesseract\n",
        "    |         |----tessdata\n",
        "    |                |---jpn.traineddata\n",
        "    |\n",
        "    ------langdata_lstm\n",
        "\n",
        "Finally, upload everything to Google Drive root folder.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j5KIFyiHABY"
      },
      "source": [
        "\n",
        "\n",
        "#1. Install Tesseract\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zGWFQbcLXhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8458de6-d762-4264-aad3-7a7a190effaa"
      },
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (9,086 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egfJBI0-HOd2"
      },
      "source": [
        "#2. Create Folders\n",
        "**train**   ▶    &nbsp;&nbsp;&nbsp;&nbsp; Data for training to be generated<br>\n",
        "**output**  ▶    &nbsp; Output of trained data<br>\n",
        "**test**  ▶    &nbsp; Test for evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWmLuBbVNDpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9434bc-8a2b-4f88-b4eb-e2551560b9c5"
      },
      "source": [
        "!mkdir output train test"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘output’: File exists\n",
            "mkdir: cannot create directory ‘train’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2WGcBOwJl0k"
      },
      "source": [
        "# 3. Add Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8w_sAtrpgVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcdb5cfc-fed1-4cdd-d16b-7d6535117481"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cZRk02wHf3F"
      },
      "source": [
        "#4. Grant Permission to Tesseract Folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMMTbc-xsXzI"
      },
      "source": [
        "!chmod 755 -R /content/drive/MyDrive/tesseract/src/training/tesstrain.sh"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Create `lstm.train` Files\n",
        "First generate `<index>.tif` and `<index>.box` files using the `.ipynb` notebook in our repo. You can modify the range to generate more `lstm.train` files.\n",
        "\n",
        "To use the `-l jpn` flag, put `jpn.traineddata` into /usr/share/tesseract-ocr/4.00/tessdata.\n",
        "\n",
        "Ignore the error regarding to `jpn_vert`, as we are only doing horizontal ocr."
      ],
      "metadata": {
        "id": "jaUgPpb5667a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "for i in {0..9}; do tesseract -l jpn /content/train/$i.tif /content/train/$i --psm 6  lstm.train; done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSXsP3K8Eu8W",
        "outputId": "c524757d-23dd-4d44-c21a-35c6b927c8d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlDBON6ulWkC"
      },
      "source": [
        "#6. Extract `jpn.lstm` from `jpn.traineddata`\n",
        "\n",
        "`jpn.lstm` will be generated from `jpn.traineddata`, which will we use as the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!combine_tessdata -e /content/drive/MyDrive/tesseract/tessdata/jpn.traineddata jpn.lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCeLsYf7Opef",
        "outputId": "6dc22306-6eb0-4738-9963-8af2cfce3621"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting tessdata components from /content/drive/MyDrive/tesseract/tessdata/jpn.traineddata\n",
            "Wrote jpn.lstm\n",
            "Version string:4.00.00alpha:jpn:synth20170629:[1,48,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]\n",
            "0:config:size=2563, offset=192\n",
            "17:lstm:size=12936715, offset=2755\n",
            "18:lstm-punc-dawg:size=2602, offset=12939470\n",
            "19:lstm-word-dawg:size=1167978, offset=12942072\n",
            "20:lstm-number-dawg:size=50, offset=14110050\n",
            "21:lstm-unicharset:size=173324, offset=14110100\n",
            "22:lstm-recoder:size=46601, offset=14283424\n",
            "23:version:size=80, offset=14330025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create `jpn.training_files.txt`\n",
        "For the content, enter the `.lstmf` files you want to train upon. Put the txt file under `/train`.\n",
        "```\n",
        "train/0.lstmf\n",
        "train/1.lstmf\n",
        "train/2.lstmf\n",
        "```"
      ],
      "metadata": {
        "id": "YITGyxcyAEDA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Beyzv0w4mdeA"
      },
      "source": [
        "#7. Train the LSTM Model\n",
        "\n",
        "Trained data will be inside `content/output` folder.\n",
        "\n",
        "Change Max Iteration as per your need. Increase this value to get less error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZddishLny8Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a807a5b-e1c0-4704-fbe7-7f79a491befa"
      },
      "source": [
        "%%shell\n",
        "\n",
        "rm -rf output/*\n",
        "OMP_THREAD_LIMIT=16 lstmtraining \\\n",
        "\t--continue_from jpn.lstm \\\n",
        "\t--model_output output/handwriting \\\n",
        "\t--traineddata /content/drive/MyDrive/tesseract/tessdata/jpn.traineddata \\\n",
        "\t--train_listfile train/jpn.training_files.txt \\\n",
        "\t--max_iterations 3000"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded file jpn.lstm, unpacking...\n",
            "Warning: LSTMTrainer deserialized an LSTMRecognizer!\n",
            "Continuing from jpn.lstm\n",
            "Loaded 30/30 lines (1-30) of document train/0.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/1.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/4.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/5.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/6.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/7.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/8.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/2.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/3.lstmf\n",
            "Loaded 30/30 lines (1-30) of document train/9.lstmf\n",
            "2 Percent improvement time=100, best error was 100 @ 0\n",
            "At iteration 100/100/100, Mean rms=1.597%, delta=14.413%, char train=60.1%, word train=100%, skip ratio=0%,  New best char error = 60.1 wrote best model:output/handwriting60.1_100.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=100, best error was 60.1 @ 100\n",
            "At iteration 200/200/200, Mean rms=1.469%, delta=12.3%, char train=51.167%, word train=100%, skip ratio=0%,  New best char error = 51.167 wrote best model:output/handwriting51.167_200.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=99, best error was 51.167 @ 200\n",
            "At iteration 299/300/300, Mean rms=1.374%, delta=10.799%, char train=44.944%, word train=100%, skip ratio=0%,  New best char error = 44.944 wrote best model:output/handwriting44.944_299.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=100, best error was 44.944 @ 299\n",
            "At iteration 399/400/400, Mean rms=1.313%, delta=9.916%, char train=41.358%, word train=100%, skip ratio=0%,  New best char error = 41.358 wrote best model:output/handwriting41.358_399.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=100, best error was 41.358 @ 399\n",
            "At iteration 499/500/500, Mean rms=1.267%, delta=9.252%, char train=38.367%, word train=100%, skip ratio=0%,  New best char error = 38.367 wrote best model:output/handwriting38.367_499.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=99, best error was 38.367 @ 499\n",
            "At iteration 598/600/600, Mean rms=1.222%, delta=8.64%, char train=35.767%, word train=99.833%, skip ratio=0%,  New best char error = 35.767 wrote best model:output/handwriting35.767_598.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=98, best error was 35.767 @ 598\n",
            "At iteration 696/700/700, Mean rms=1.182%, delta=8.143%, char train=33.695%, word train=99.571%, skip ratio=0%,  New best char error = 33.695 wrote best model:output/handwriting33.695_696.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=195, best error was 35.767 @ 598\n",
            "At iteration 793/800/800, Mean rms=1.153%, delta=7.779%, char train=32.121%, word train=99.375%, skip ratio=0%,  New best char error = 32.121 wrote best model:output/handwriting32.121_793.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=195, best error was 33.695 @ 696\n",
            "At iteration 891/900/900, Mean rms=1.121%, delta=7.39%, char train=30.481%, word train=99.222%, skip ratio=0%,  New best char error = 30.481 wrote best model:output/handwriting30.481_891.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=193, best error was 32.121 @ 793\n",
            "At iteration 986/1000/1000, Mean rms=1.091%, delta=7.051%, char train=29.06%, word train=98.9%, skip ratio=0%,  New best char error = 29.06 wrote best model:output/handwriting29.06_986.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=93, best error was 29.06 @ 986\n",
            "At iteration 1079/1100/1100, Mean rms=1.016%, delta=6.026%, char train=24.753%, word train=98.4%, skip ratio=0%,  New best char error = 24.753 wrote best model:output/handwriting24.753_1079.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=93, best error was 24.753 @ 1079\n",
            "At iteration 1172/1200/1200, Mean rms=0.958%, delta=5.346%, char train=21.933%, word train=97.8%, skip ratio=0%,  New best char error = 21.933 wrote best model:output/handwriting21.933_1172.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=182, best error was 24.753 @ 1079\n",
            "At iteration 1261/1300/1300, Mean rms=0.91%, delta=4.862%, char train=19.94%, word train=96.6%, skip ratio=0%,  New best char error = 19.94 wrote best model:output/handwriting19.94_1261.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=181, best error was 21.933 @ 1172\n",
            "At iteration 1353/1400/1400, Mean rms=0.872%, delta=4.47%, char train=18.207%, word train=95.7%, skip ratio=0%,  New best char error = 18.207 wrote best model:output/handwriting18.207_1353.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=181, best error was 19.94 @ 1261\n",
            "At iteration 1442/1500/1500, Mean rms=0.832%, delta=4.084%, char train=16.713%, word train=94.8%, skip ratio=0%,  New best char error = 16.713 wrote best model:output/handwriting16.713_1442.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=173, best error was 18.207 @ 1353\n",
            "At iteration 1526/1600/1600, Mean rms=0.794%, delta=3.759%, char train=15.433%, word train=93.5%, skip ratio=0%,  New best char error = 15.433 wrote best model:output/handwriting15.433_1526.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=165, best error was 16.713 @ 1442\n",
            "At iteration 1607/1700/1700, Mean rms=0.766%, delta=3.518%, char train=14.35%, word train=92.3%, skip ratio=0%,  New best char error = 14.35 wrote best model:output/handwriting14.35_1607.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=163, best error was 15.433 @ 1526\n",
            "At iteration 1689/1800/1800, Mean rms=0.731%, delta=3.223%, char train=13.15%, word train=90.7%, skip ratio=0%,  New best char error = 13.15 wrote best model:output/handwriting13.15_1689.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=155, best error was 14.35 @ 1607\n",
            "At iteration 1762/1900/1900, Mean rms=0.698%, delta=2.963%, char train=12.203%, word train=88.6%, skip ratio=0%,  New best char error = 12.203 wrote best model:output/handwriting12.203_1762.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=233, best error was 14.35 @ 1607\n",
            "At iteration 1840/2000/2000, Mean rms=0.674%, delta=2.777%, char train=11.44%, word train=86.8%, skip ratio=0%,  New best char error = 11.44 wrote best model:output/handwriting11.44_1840.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=228, best error was 13.15 @ 1689\n",
            "At iteration 1917/2100/2100, Mean rms=0.643%, delta=2.54%, char train=10.433%, word train=84.9%, skip ratio=0%,  New best char error = 10.433 wrote best model:output/handwriting10.433_1917.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=221, best error was 12.203 @ 1762\n",
            "At iteration 1983/2200/2200, Mean rms=0.612%, delta=2.33%, char train=9.613%, word train=82.1%, skip ratio=0%,  New best char error = 9.613 Transitioned to stage 1 wrote best model:output/handwriting9.613_1983.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=210, best error was 11.44 @ 1840\n",
            "At iteration 2050/2300/2300, Mean rms=0.592%, delta=2.201%, char train=9.05%, word train=80.4%, skip ratio=0%,  New best char error = 9.05 wrote best model:output/handwriting9.05_2050.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=199, best error was 10.433 @ 1917\n",
            "At iteration 2116/2400/2400, Mean rms=0.564%, delta=2.005%, char train=8.28%, word train=77.9%, skip ratio=0%,  New best char error = 8.28 wrote best model:output/handwriting8.28_2116.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=192, best error was 9.613 @ 1983\n",
            "At iteration 2175/2500/2500, Mean rms=0.535%, delta=1.834%, char train=7.603%, word train=74.6%, skip ratio=0%,  New best char error = 7.603 wrote best model:output/handwriting7.603_2175.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=250, best error was 9.613 @ 1983\n",
            "At iteration 2233/2600/2600, Mean rms=0.517%, delta=1.73%, char train=7.113%, word train=71.9%, skip ratio=0%,  New best char error = 7.113 wrote best model:output/handwriting7.113_2233.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=236, best error was 9.05 @ 2050\n",
            "At iteration 2286/2700/2700, Mean rms=0.491%, delta=1.56%, char train=6.507%, word train=69.3%, skip ratio=0%,  New best char error = 6.507 wrote best model:output/handwriting6.507_2286.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=210, best error was 8.28 @ 2116\n",
            "At iteration 2326/2800/2800, Mean rms=0.463%, delta=1.404%, char train=5.957%, word train=65.7%, skip ratio=0%,  New best char error = 5.957 wrote best model:output/handwriting5.957_2326.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=262, best error was 8.28 @ 2116\n",
            "At iteration 2378/2900/2900, Mean rms=0.448%, delta=1.334%, char train=5.607%, word train=63.8%, skip ratio=0%,  New best char error = 5.607 wrote best model:output/handwriting5.607_2378.checkpoint wrote checkpoint.\n",
            "\n",
            "2 Percent improvement time=187, best error was 7.113 @ 2233\n",
            "At iteration 2420/3000/3000, Mean rms=0.423%, delta=1.197%, char train=5.077%, word train=60.6%, skip ratio=0%,  New best char error = 5.077 wrote best model:output/handwriting5.077_2420.checkpoint wrote checkpoint.\n",
            "\n",
            "Finished! Error rate = 5.077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_gREJArnCl2"
      },
      "source": [
        "#8. Get the Trained Model\n",
        "\n",
        "This command will create trained data from `fontname.checkpoint`.\n",
        "This will be inside `content/output` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wPmBN9IM7Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a850ace-3af5-43a0-d00e-5beec9869348"
      },
      "source": [
        "%%shell\n",
        "\n",
        "lstmtraining --stop_training \\\n",
        "\t--continue_from output/handwriting_checkpoint \\\n",
        "\t--traineddata /content/drive/MyDrive/tesseract/tessdata/jpn.traineddata \\\n",
        "\t--model_output output/handwriting.traineddata"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded file output/handwriting_checkpoint, unpacking...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Model Inference\n",
        "\n",
        "Download and paste the `handwriting.traineddata` inside this folder on a linux machine:\n",
        "\n",
        "/usr/share/tesseract-ocr/4.00/tessdata\n",
        "\n",
        "You can put your `.jpg` image anywhere in the colab. Modify the following code to generate the prediction `.txt`.\n",
        "\n",
        "For different `psm` flag options, see: https://pyimagesearch.com/2021/11/15/tesseract-page-segmentation-modes-psms-explained-how-to-improve-your-ocr-accuracy/"
      ],
      "metadata": {
        "id": "7X51C1W-_kdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tesseract /content/test/test.jpg /content/test/predict -l handwriting --psm 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P76ti9G0RJ_",
        "outputId": "8eae4e66-0271-49e0-e0e0-29ef41e7f185"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error opening data file /usr/share/tesseract-ocr/4.00/tessdata/jpn_vert.traineddata\n",
            "Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\n",
            "Failed loading language 'jpn_vert'\n",
            "Tesseract Open Source OCR Engine v4.1.1 with Leptonica\n",
            "Warning: Invalid resolution 0 dpi. Using 70 instead.\n"
          ]
        }
      ]
    }
  ]
}