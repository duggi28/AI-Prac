{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04c74f6-e9a5-4100-ba63-adac174ecbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0x3042', 1: '0x3044', 2: '0x3046', 3: '0x3048', 4: '0x304a', 5: '0x304b', 6: '0x304c', 7: '0x304d', 8: '0x304e', 9: '0x304f', 10: '0x3050', 11: '0x3051', 12: '0x3052', 13: '0x3053', 14: '0x3054', 15: '0x3055', 16: '0x3056', 17: '0x3057', 18: '0x3058', 19: '0x3059', 20: '0x305a', 21: '0x305b', 22: '0x305c', 23: '0x305d', 24: '0x305e', 25: '0x305f', 26: '0x3060', 27: '0x3061', 28: '0x3062', 29: '0x3064', 30: '0x3065', 31: '0x3066', 32: '0x3067', 33: '0x3068', 34: '0x3069', 35: '0x306a', 36: '0x306b', 37: '0x306c', 38: '0x306d', 39: '0x306e', 40: '0x306f', 41: '0x3070', 42: '0x3071', 43: '0x3072', 44: '0x3073', 45: '0x3074', 46: '0x3075', 47: '0x3076', 48: '0x3077', 49: '0x3078', 50: '0x3079', 51: '0x307a', 52: '0x307b', 53: '0x307c', 54: '0x307d', 55: '0x307e', 56: '0x307f', 57: '0x3080', 58: '0x3081', 59: '0x3082', 60: '0x3084', 61: '0x3086', 62: '0x3088', 63: '0x3089', 64: '0x308a', 65: '0x308b', 66: '0x308c', 67: '0x308d', 68: '0x308f', 69: '0x3092', 70: '0x3093'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "unicode_to_class={}\n",
    "class_to_unicode={}\n",
    "# count=0\n",
    "# IMG_DIR = '/Users/yichen/Documents/Cornell/06_2024sp/cs4701/code/data/ETL8'\n",
    "# for dir in os.listdir(IMG_DIR):\n",
    "#     if dir==\".DS_Store\":\n",
    "#         continue\n",
    "#     unicode_to_class[dir]=count\n",
    "#     class_to_unicode[count]=dir\n",
    "#     count+=1\n",
    "unicodes=[\"3042\", \"3044\", \"3046\", \"3048\", \"304a\", \"304b\", \"304c\", \"304d\", \"304e\", \"304f\", \"3050\", \"3051\", \"3052\", \"3053\", \"3054\", \"3055\", \"3056\", \"3057\", \"3058\", \"3059\", \"305a\", \"305b\", \"305c\", \"305d\", \"305e\", \"305f\", \"3060\", \"3061\", \"3062\", \"3064\", \"3065\", \"3066\", \"3067\", \"3068\", \"3069\", \"306a\", \"306b\", \"306c\", \"306d\", \"306e\", \"306f\", \"3070\", \"3071\", \"3072\", \"3073\", \"3074\", \"3075\", \"3076\", \"3077\", \"3078\", \"3079\", \"307a\", \"307b\", \"307c\", \"307d\", \"307e\", \"307f\", \"3080\", \"3081\", \"3082\", \"3084\", \"3086\", \"3088\", \"3089\", \"308a\", \"308b\", \"308c\", \"308d\", \"308f\", \"3092\", \"3093\"]\n",
    "count=0\n",
    "for u in unicodes:\n",
    "    hex=\"0x\"+u\n",
    "    unicode_to_class[hex]=count\n",
    "    class_to_unicode[count]=hex\n",
    "    count+=1\n",
    "print(class_to_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25df5b5a-d0cf-43bc-a817-b652cf523767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL8 0x305a 20\n",
      "ETL8 0x305f 25\n",
      "ETL8 0x3056 16\n",
      "ETL8 0x3069 34\n",
      "ETL8 0x3051 11\n",
      "ETL8 0x3067 32\n",
      "ETL8 0x3093 70\n",
      "ETL8 0x3058 18\n",
      "ETL8 0x3060 26\n",
      "ETL8 0x306f 40\n",
      "ETL8 0x306a 35\n",
      "ETL8 0x3061 27\n",
      "ETL8 0x3092 69\n",
      "ETL8 0x3066 31\n",
      "ETL8 0x3059 19\n",
      "ETL8 0x3050 10\n",
      "ETL8 0x3057 17\n",
      "ETL8 0x3068 33\n",
      "ETL8 0x3075 46\n",
      "ETL8 0x3081 58\n",
      "ETL8 0x3086 61\n",
      "ETL8 0x3072 43\n",
      "ETL8 0x3044 1\n",
      "ETL8 0x3088 62\n",
      "ETL8 0x307b 52\n",
      "ETL8 0x308f 68\n",
      "ETL8 0x308a 64\n",
      "ETL8 0x307e 55\n",
      "ETL8 0x304c 6\n",
      "ETL8 0x304d 7\n",
      "ETL8 0x3089 63\n",
      "ETL8 0x3042 0\n",
      "ETL8 0x3073 44\n",
      "ETL8 0x3080 57\n",
      "ETL8 0x3074 45\n",
      "ETL8 0x304e 8\n",
      "ETL8 0x304b 5\n",
      "ETL8 0x307d 54\n",
      "ETL8 0x307c 53\n",
      "ETL8 0x3052 12\n",
      "ETL8 0x3055 15\n",
      "ETL8 0x3064 29\n",
      "ETL8 0x305e 24\n",
      "ETL8 0x305b 21\n",
      "ETL8 0x306d 38\n",
      "ETL8 0x306c 37\n",
      "ETL8 0x3065 30\n",
      "ETL8 0x3062 28\n",
      "ETL8 0x3054 14\n",
      "ETL8 0x3053 13\n",
      "ETL8 0x306b 36\n",
      "ETL8 0x306e 39\n",
      "ETL8 0x305c 22\n",
      "ETL8 0x305d 23\n",
      "ETL8 0x308b 65\n",
      "ETL8 0x307f 56\n",
      "ETL8 0x307a 51\n",
      "ETL8 0x3071 42\n",
      "ETL8 0x3076 47\n",
      "ETL8 0x3082 59\n",
      "ETL8 0x3078 49\n",
      "ETL8 0x304a 4\n",
      "ETL8 0x304f 9\n",
      "ETL8 0x308d 67\n",
      "ETL8 0x308c 66\n",
      "ETL8 0x3079 50\n",
      "ETL8 0x3046 2\n",
      "ETL8 0x3048 3\n",
      "ETL8 0x3077 48\n",
      "ETL8 0x3070 41\n",
      "ETL8 0x3084 60\n",
      "ETL9 0x305a 20\n",
      "ETL9 0x305f 25\n",
      "ETL9 0x3056 16\n",
      "ETL9 0x3069 34\n",
      "ETL9 0x3051 11\n",
      "ETL9 0x3067 32\n",
      "ETL9 0x3093 70\n",
      "ETL9 0x3058 18\n",
      "ETL9 0x3060 26\n",
      "ETL9 0x306f 40\n",
      "ETL9 0x306a 35\n",
      "ETL9 0x3061 27\n",
      "ETL9 0x3092 69\n",
      "ETL9 0x3066 31\n",
      "ETL9 0x3059 19\n",
      "ETL9 0x3050 10\n",
      "ETL9 0x3057 17\n",
      "ETL9 0x3068 33\n",
      "ETL9 0x3075 46\n",
      "ETL9 0x3081 58\n",
      "ETL9 0x3086 61\n",
      "ETL9 0x3072 43\n",
      "ETL9 0x3044 1\n",
      "ETL9 0x3088 62\n",
      "ETL9 0x307b 52\n",
      "ETL9 0x308f 68\n",
      "ETL9 0x308a 64\n",
      "ETL9 0x307e 55\n",
      "ETL9 0x304c 6\n",
      "ETL9 0x304d 7\n",
      "ETL9 0x3089 63\n",
      "ETL9 0x3042 0\n",
      "ETL9 0x3073 44\n",
      "ETL9 0x3080 57\n",
      "ETL9 0x3074 45\n",
      "ETL9 0x304e 8\n",
      "ETL9 0x304b 5\n",
      "ETL9 0x307d 54\n",
      "ETL9 0x307c 53\n",
      "ETL9 0x3052 12\n",
      "ETL9 0x3055 15\n",
      "ETL9 0x3064 29\n",
      "ETL9 0x305e 24\n",
      "ETL9 0x305b 21\n",
      "ETL9 0x306d 38\n",
      "ETL9 0x306c 37\n",
      "ETL9 0x3065 30\n",
      "ETL9 0x3062 28\n",
      "ETL9 0x3054 14\n",
      "ETL9 0x3053 13\n",
      "ETL9 0x306b 36\n",
      "ETL9 0x306e 39\n",
      "ETL9 0x305c 22\n",
      "ETL9 0x305d 23\n",
      "ETL9 0x308b 65\n",
      "ETL9 0x307f 56\n",
      "ETL9 0x307a 51\n",
      "ETL9 0x3071 42\n",
      "ETL9 0x3076 47\n",
      "ETL9 0x3082 59\n",
      "ETL9 0x3078 49\n",
      "ETL9 0x304a 4\n",
      "ETL9 0x304f 9\n",
      "ETL9 0x308d 67\n",
      "ETL9 0x308c 66\n",
      "ETL9 0x3079 50\n",
      "ETL9 0x3046 2\n",
      "ETL9 0x3048 3\n",
      "ETL9 0x3077 48\n",
      "ETL9 0x3070 41\n",
      "ETL9 0x3084 60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_DIR = '/data' #need to modify this\n",
    "label_array=[]\n",
    "\n",
    "for dataset in os.listdir(IMG_DIR):\n",
    "    if dataset !=\"ETL8\" and dataset !=\"ETL9\":\n",
    "        continue\n",
    "    \n",
    "    for unicode in os.listdir(os.path.join(IMG_DIR,dataset)):\n",
    "        if unicode ==\".DS_Store\":\n",
    "            continue\n",
    "        print(dataset,unicode,unicode_to_class[unicode])\n",
    "        \n",
    "        for img in os.listdir(os.path.join(IMG_DIR,dataset,unicode)):\n",
    "            if img[-4:]!=\".png\":\n",
    "                continue\n",
    "            img_array = cv2.imread(os.path.join(IMG_DIR,dataset,unicode,img), cv2.IMREAD_GRAYSCALE)\n",
    "            if dataset==\"ETL9\":\n",
    "                img_array=img_array[10:118, 10:117]\n",
    "            img_array = cv2.resize(img_array, (48, 48))\n",
    "            img_array = (img_array.flatten())\n",
    "            img_array  = img_array.reshape(-1, 1).T\n",
    "            \n",
    "            with open('images.csv', 'ab') as f:\n",
    "                np.savetxt(f, img_array, delimiter=\",\")\n",
    "            \n",
    "            label_array.append(unicode_to_class[unicode])\n",
    "        \n",
    "df = pd.DataFrame([*zip(label_array)])\n",
    "df.to_csv('labels.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54a3d3f7-d829-44b8-b612-ea441e22ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "images = pd.read_csv(\"images.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ee3fe7f-9ab3-4a34-878a-f5449fbf49f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25626</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25627</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25628</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25629</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25630</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25631 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9     \\\n",
       "0      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "1      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "2      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "3      255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "4      252.0  252.0  252.0  252.0  252.0  252.0  252.0  252.0  252.0  252.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "25626  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "25627  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "25628  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "25629  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "25630  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "\n",
       "       ...   2294   2295   2296   2297   2298   2299   2300   2301   2302  \\\n",
       "0      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "1      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "2      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "3      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "4      ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "25626  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "25627  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "25628  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "25629  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "25630  ...  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "\n",
       "        2303  \n",
       "0      255.0  \n",
       "1      255.0  \n",
       "2      255.0  \n",
       "3      255.0  \n",
       "4      255.0  \n",
       "...      ...  \n",
       "25626  255.0  \n",
       "25627  255.0  \n",
       "25628  255.0  \n",
       "25629  255.0  \n",
       "25630  255.0  \n",
       "\n",
       "[25631 rows x 2304 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6e2831e-c96e-4989-a149-d5b984250c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25626</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25627</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25628</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25629</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25630</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25631 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0      20\n",
       "1      20\n",
       "2      20\n",
       "3      20\n",
       "4      20\n",
       "...    ..\n",
       "25626  60\n",
       "25627  60\n",
       "25628  60\n",
       "25629  60\n",
       "25630  60\n",
       "\n",
       "[25631 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"labels.csv\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3b4400d-aaf7-4a56-811f-d4e20613d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import skimage.transform\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "905fdd9d-cafe-4c2d-9357-ee7308760b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines ratios, w.r.t. whole dataset.\n",
    "ratio_train = 0.8\n",
    "ratio_val = 0.1\n",
    "ratio_test = 0.1\n",
    "images=images.values/255\n",
    "\n",
    "labels=labels.values.reshape(labels.shape[0])\n",
    "images_train, images_val, labels_train, labels_val = train_test_split(\n",
    "    images, labels, test_size=0.2)\n",
    "\n",
    "# # Produces test split.\n",
    "# images_remaining, images_test, labels_remaining, label_test = train_test_split(\n",
    "#     images, labels, test_size=ratio_test)\n",
    "\n",
    "# # Adjusts val ratio, w.r.t. remaining dataset.\n",
    "# ratio_remaining = 1 - ratio_test\n",
    "# ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "\n",
    "# Produces train and val splits.\n",
    "# images_train, images_val, labels_train, labels_val = train_test_split(\n",
    "#     images_remaining, labels_remaining, test_size=ratio_val_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a58aab7-5d11-4123-b7e5-73f190f1c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "138bb677-6b98-4869-b3c9-2e60c97675a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20504, 2304)\n",
      "(20504,)\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2809a79d-2e74-411f-8eaf-f4d6f4475b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGeCAYAAADSRtWEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaQElEQVR4nO3dfXBUdb7n8U9Ckg6SdAdQOmaTQCwfkKLAIgr0dXYeIGOGUhaG3LrOjrXDKLU+tSyQu+WQrRF3dmcqlOOVhzE8rLKwsyviZWrAwSpx2Cih5k4SIUiBDxOdFSW70GGsMt0hmpCb/PYPta8t6eN0CHy7w/tVdaqG8+3T/OYMkzcnnJPOcs45AQBwmWVbLwAAcGUiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYyLFewFcNDg7q9OnTKiwsVFZWlvVyAAApcs6pu7tbJSUlys72uM5xl8jTTz/tJk+e7Hw+n5s9e7ZrbW39q47r6OhwktjY2NjYMnzr6Ojw/Hp/Sa6AXnjhBdXW1mrLli2aM2eO1q9fr+rqarW3t2vSpEmexxYWFkqSPjw6Rf4CvkMIAJkmdm5Qk2d9EP96nkyWcyP/w0jnzJmj2267TU8//bSkz76tVlZWpuXLl2v16tWex8ZiMQUCAX387nXyFxIgAMg0se5Bjb/xfUWjUfn9/qSvG/Gv8OfPn1dbW5uqqqr+5TfJzlZVVZWam5sveH1fX59isVjCBgAY/UY8QB999JEGBgYUDAYT9geDQUUikQteX19fr0AgEN/KyspGekkAgDRk/j2uuro6RaPR+NbR0WG9JADAZTDiNyFcffXVGjNmjDo7OxP2d3Z2qri4+ILX+3w++Xy+kV4GACDNjfgVUF5eniorK9XY2BjfNzg4qMbGRoVCoZH+7QAAGeqS3IZdW1urpUuX6tZbb9Xs2bO1fv169fT06N57770Uvx0AIANdkgDdfffd+stf/qI1a9YoEonolltu0f79+y+4MQEAcOW6JM8BXQyeAwKAzGb2HBAAAH8NAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwkXKADh06pIULF6qkpERZWVnau3dvwtw5pzVr1ujaa6/V2LFjVVVVpffee2+k1gsAGCVSDlBPT49mzpyphoaGIedPPPGENm7cqC1btqi1tVXjxo1TdXW1ent7L3qxAIDRIyfVAxYsWKAFCxYMOXPOaf369frpT3+qRYsWSZJ+/etfKxgMau/evfrBD35wcasFAIwaI/pvQCdPnlQkElFVVVV8XyAQ0Jw5c9Tc3DzkMX19fYrFYgkbAGD0G9EARSIRSVIwGEzYHwwG47Ovqq+vVyAQiG9lZWUjuSQAQJoyvwuurq5O0Wg0vnV0dFgvCQBwGYxogIqLiyVJnZ2dCfs7Ozvjs6/y+Xzy+/0JGwBg9BvRAFVUVKi4uFiNjY3xfbFYTK2trQqFQiP5WwEAMlzKd8GdO3dOf/7zn+O/PnnypI4dO6YJEyaovLxcK1eu1M9//nPdcMMNqqio0GOPPaaSkhItXrx4JNcNAMhwKQfoyJEj+s53vhP/dW1trSRp6dKl2rFjhx599FH19PTo/vvvV1dXl77xjW9o//79ys/PH7lVAwAyXpZzzlkv4stisZgCgYA+fvc6+QvN75EAAKQo1j2o8Te+r2g06vnv+nyFBwCYIEAAABMECABgIuWbEACkt//Tf85z/vcf1HjO997wykguB0iKKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCC54CADPN1z/nctf1Rz/mUPR97zqcveDjp7M3/sMnzWCAVXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATPAcEpKFT/5z8WZ+Fz3g/51P+8z96zrMrJnvOeyYXes6BkcIVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMFzQICBPtfvOV+wJfmzPpPXH/M8Nuuaazzn76wq9pyfXLTVcw6MFK6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwGzZgoLL1x57zKf/jg+TDSVd7HvvBD0s95+//7SbPOXC5cAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM8BwQcAm83uf9cQvlq3s95677XNJZ9HvTPI89Gt7gOZdyv2YOXB5cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABM8BwQM07nB5M/yrPm7f+95bLY+8Zy78pKks988+aTnsb6sAs85kC64AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwW3YQBJet1lL0i3Pr0o6u7H9Lc9jB6ZN8ZxP2fhe0tm1OdxmjdGBKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCC54CAJKrf/KHn/Mb/mvxZHzcw4Hnsu/f5POevlDZ7zoHRIKUroPr6et12220qLCzUpEmTtHjxYrW3tye8pre3V+FwWBMnTlRBQYFqamrU2dk5oosGAGS+lALU1NSkcDislpYWHThwQP39/brjjjvU09MTf82qVau0b98+7d69W01NTTp9+rSWLFky4gsHAGS2lL4Ft3///oRf79ixQ5MmTVJbW5u++c1vKhqNatu2bdq5c6fmzZsnSdq+fbtuvvlmtbS0aO7cuSO3cgBARruomxCi0agkacKECZKktrY29ff3q6qqKv6aqVOnqry8XM3NQ39Pu6+vT7FYLGEDAIx+ww7Q4OCgVq5cqdtvv13Tp0+XJEUiEeXl5amoqCjhtcFgUJFIZMj3qa+vVyAQiG9lZWXDXRIAIIMMO0DhcFhvvvmmdu3adVELqKurUzQajW8dHR0X9X4AgMwwrNuwH3nkEb300ks6dOiQSktL4/uLi4t1/vx5dXV1JVwFdXZ2qri4eMj38vl88vm8b0kFAIw+KQXIOafly5drz549OnjwoCoqKhLmlZWVys3NVWNjo2pqaiRJ7e3tOnXqlEKh0MitGhgB7/b3eM6znr3Gcz4Qez/prOvfef95P3nXZs85cCVIKUDhcFg7d+7Uiy++qMLCwvi/6wQCAY0dO1aBQEDLli1TbW2tJkyYIL/fr+XLlysUCnEHHAAgQUoB2rz5s7+1ffvb307Yv337dv34xz+WJK1bt07Z2dmqqalRX1+fqqurtWnTphFZLABg9Ej5W3BfJz8/Xw0NDWpoaBj2ogAAox8/jBQAYIIAAQBMECAAgAkCBAAwkbafB9Tn+tXnhu6jLyv3Mq8Go9H39tV6zqce/8hz3jevMuns7x/bOaw1AVcSroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATKTtbdj/+vA9GnPV0J8TdHzu/0x63JgsmorPVL9zl+f85ifPeM4HrvZ7zk8uTf6zEReN876FW+JRAoCv1gAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETaPgdU+LsCjcnLH3K2b0by5zMWjzt3qZaEDHP2t+We85L+DzznH97l/RzQO1Ubks74yBDg63EFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATKTtc0DX3f+ucsflDTmb44t4HFlwaRaEjFO34jnP+Y4DVZ7z3pJ+zznP+gAXhysgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNZzjlnvYgvi8ViCgQC+vjd6+QvpI+4dKZtethzXvHc//Oc9z6T/P86jdN+N6w1AaNBrHtQ4298X9FoVH5/8o814Ss8AMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwkbYfxwBcav/0wJOe87verfWcX/Wfe5POfrf9Ks9j/824TzznwJWAKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCzwMCktjbU+A5b7j3b5PO+v25nscefPaZYa0JyAR8HhAAIK0RIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATfB4QkMTicec8579Ynfwzfa551Pu9r/vtA57z95ds9X4DYBTgCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABLdhA8N0eNY/Jp3d+jcPeR478aj3ezcuGJN0Nn/sgPfBQIZI6Qpo8+bNmjFjhvx+v/x+v0KhkF5++eX4vLe3V+FwWBMnTlRBQYFqamrU2dk54osGAGS+lAJUWlqqtWvXqq2tTUeOHNG8efO0aNEivfXWW5KkVatWad++fdq9e7eampp0+vRpLVmy5JIsHACQ2VL6FtzChQsTfv2LX/xCmzdvVktLi0pLS7Vt2zbt3LlT8+bNkyRt375dN998s1paWjR37tyRWzUAIOMN+yaEgYEB7dq1Sz09PQqFQmpra1N/f7+qqqrir5k6darKy8vV3Nyc9H36+voUi8USNgDA6JdygE6cOKGCggL5fD49+OCD2rNnj6ZNm6ZIJKK8vDwVFRUlvD4YDCoSiSR9v/r6egUCgfhWVlaW8n8JAEDmSTlAN910k44dO6bW1lY99NBDWrp0qd5+++1hL6Curk7RaDS+dXR0DPu9AACZI+XbsPPy8nT99ddLkiorK3X48GFt2LBBd999t86fP6+urq6Eq6DOzk4VFxcnfT+fzyefz5f6ygEAGe2inwMaHBxUX1+fKisrlZubq8bGRtXU1EiS2tvbderUKYVCoYteKJBJdj72pOf8gQdWes5Xbk7+cQ0najcNZ0lA2kkpQHV1dVqwYIHKy8vV3d2tnTt36uDBg3rllVcUCAS0bNky1dbWasKECfL7/Vq+fLlCoRB3wAEALpBSgM6ePasf/ehHOnPmjAKBgGbMmKFXXnlF3/3udyVJ69atU3Z2tmpqatTX16fq6mpt2sTf1gAAF0opQNu2bfOc5+fnq6GhQQ0NDRe1KADA6McPIwUAmCBAAAATBAgAYIIAAQBM8HlAwCVwY+44z/kHi7M85+Uv/XPS2QP/1/u5uq2lyX/2IpBOuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMFt2ICBE3dt9Jx/463a5Mc+NdPz2HNPvuY5L8jO95wDlwtXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwATPAQEGvu5ZnMp7jiednbn3Ws9jHzz1Pc/5/5py0HMOXC5cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABM8BwSkoQ2l/zvp7Lu3rPQ89tP/UuT95v/9YMrrAS4FroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAbNpCGvD6u4W/+4+uex759302e88q2v/Oct1X+o+ccGClcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABM8BwRkmH+49qjn/Nv/qtJzXrA1y/s3+G+prggYHq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACZ4DAkaZ9Q1Pe87/U/UPPeczXv+3SWfHZz8/rDUBQ+EKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOA5IGCUucXn85xHNzrPec+fAsmHs4ezImBoXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOA2bOAK808zfuv9ghmXZx3ARV0BrV27VllZWVq5cmV8X29vr8LhsCZOnKiCggLV1NSos7PzYtcJABhlhh2gw4cPa+vWrZoxI/GvS6tWrdK+ffu0e/duNTU16fTp01qyZMlFLxQAMLoMK0Dnzp3TPffco2eeeUbjx4+P749Go9q2bZueeuopzZs3T5WVldq+fbv++Mc/qqWlZcQWDQDIfMMKUDgc1p133qmqqqqE/W1tberv70/YP3XqVJWXl6u5uXnI9+rr61MsFkvYAACjX8o3IezatUtHjx7V4cOHL5hFIhHl5eWpqKgoYX8wGFQkEhny/err6/Wzn/0s1WUAADJcSldAHR0dWrFihZ577jnl5+ePyALq6uoUjUbjW0dHx4i8LwAgvaUUoLa2Np09e1azZs1STk6OcnJy1NTUpI0bNyonJ0fBYFDnz59XV1dXwnGdnZ0qLi4e8j19Pp/8fn/CBgAY/VL6Ftz8+fN14sSJhH333nuvpk6dqp/85CcqKytTbm6uGhsbVVNTI0lqb2/XqVOnFAqFRm7VAICMl1KACgsLNX369IR948aN08SJE+P7ly1bptraWk2YMEF+v1/Lly9XKBTS3LlzR27VAICMN+I/CWHdunXKzs5WTU2N+vr6VF1drU2bNo30bwMAyHBZzjnvj0e8zGKxmAKBgD5+9zr5C/lRdQCQaWLdgxp/4/uKRqOe/67PV3gAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIkc6wV8lXNOkhQ7N2i8EgDAcHzx9fuLr+fJpF2Auru7JUmTZ31guxAAwEXp7u5WIBBIOs9yX5eoy2xwcFCnT59WYWGhsrKyFIvFVFZWpo6ODvn9fuvlZQTOWeo4Z6njnKXuSjlnzjl1d3erpKRE2dnJ/6Un7a6AsrOzVVpaesF+v98/qv8HuxQ4Z6njnKWOc5a6K+GceV35fIGbEAAAJggQAMBE2gfI5/Pp8ccfl8/ns15KxuCcpY5zljrOWeo4Z4nS7iYEAMCVIe2vgAAAoxMBAgCYIEAAABMECABgggABAEykfYAaGho0ZcoU5efna86cOXr99detl5Q2Dh06pIULF6qkpERZWVnau3dvwtw5pzVr1ujaa6/V2LFjVVVVpffee89msWmgvr5et912mwoLCzVp0iQtXrxY7e3tCa/p7e1VOBzWxIkTVVBQoJqaGnV2dhqtOD1s3rxZM2bMiD+9HwqF9PLLL8fnnDNva9euVVZWllauXBnfxzn7TFoH6IUXXlBtba0ef/xxHT16VDNnzlR1dbXOnj1rvbS00NPTo5kzZ6qhoWHI+RNPPKGNGzdqy5Ytam1t1bhx41RdXa3e3t7LvNL00NTUpHA4rJaWFh04cED9/f2644471NPTE3/NqlWrtG/fPu3evVtNTU06ffq0lixZYrhqe6WlpVq7dq3a2tp05MgRzZs3T4sWLdJbb70liXPm5fDhw9q6datmzJiRsJ9z9jmXxmbPnu3C4XD81wMDA66kpMTV19cbrio9SXJ79uyJ/3pwcNAVFxe7X/7yl/F9XV1dzufzueeff95ghenn7NmzTpJrampyzn12fnJzc93u3bvjr3nnnXecJNfc3Gy1zLQ0fvx49+yzz3LOPHR3d7sbbrjBHThwwH3rW99yK1ascM7x5+zL0vYK6Pz582pra1NVVVV8X3Z2tqqqqtTc3Gy4ssxw8uRJRSKRhPMXCAQ0Z84czt/notGoJGnChAmSpLa2NvX39yecs6lTp6q8vJxz9rmBgQHt2rVLPT09CoVCnDMP4XBYd955Z8K5kfhz9mVp99Owv/DRRx9pYGBAwWAwYX8wGNSf/vQno1VljkgkIklDnr8vZleywcFBrVy5UrfffrumT58u6bNzlpeXp6KiooTXcs6kEydOKBQKqbe3VwUFBdqzZ4+mTZumY8eOcc6GsGvXLh09elSHDx++YMafs3+RtgECLqVwOKw333xTf/jDH6yXkhFuuukmHTt2TNFoVL/5zW+0dOlSNTU1WS8rLXV0dGjFihU6cOCA8vPzrZeT1tL2W3BXX321xowZc8GdIZ2dnSouLjZaVeb44hxx/i70yCOP6KWXXtJrr72W8NlTxcXFOn/+vLq6uhJezzmT8vLydP3116uyslL19fWaOXOmNmzYwDkbQltbm86ePatZs2YpJydHOTk5ampq0saNG5WTk6NgMMg5+1zaBigvL0+VlZVqbGyM7xscHFRjY6NCoZDhyjJDRUWFiouLE85fLBZTa2vrFXv+nHN65JFHtGfPHr366quqqKhImFdWVio3NzfhnLW3t+vUqVNX7DlLZnBwUH19fZyzIcyfP18nTpzQsWPH4tutt96qe+65J/6fOWefs74LwsuuXbucz+dzO3bscG+//ba7//77XVFRkYtEItZLSwvd3d3ujTfecG+88YaT5J566in3xhtvuA8//NA559zatWtdUVGRe/HFF93x48fdokWLXEVFhfv000+NV27joYcecoFAwB08eNCdOXMmvn3yySfx1zz44IOuvLzcvfrqq+7IkSMuFAq5UChkuGp7q1evdk1NTe7kyZPu+PHjbvXq1S4rK8v9/ve/d85xzv4aX74LzjnO2RfSOkDOOferX/3KlZeXu7y8PDd79mzX0tJivaS08dprrzlJF2xLly51zn12K/Zjjz3mgsGg8/l8bv78+a69vd120YaGOleS3Pbt2+Ov+fTTT93DDz/sxo8f76666ir3/e9/3505c8Zu0Wngvvvuc5MnT3Z5eXnummuucfPnz4/HxznO2V/jqwHinH2GzwMCAJhI238DAgCMbgQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz8fyGH6j4mCS4CAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "0x304f\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a=images_train[0]\n",
    "a=images_train[0].reshape(48,48)\n",
    "print(a)\n",
    "plt.imshow(a)\n",
    "plt.show()\n",
    "print(labels_train[0])\n",
    "print(class_to_unicode[labels_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3f38e69-e5f1-4e90-97bd-d48f40212b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "(48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape images\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "  images_train = images_train.reshape(images_train.shape[0], 1,48,48)\n",
    "  images_val = images_val.reshape(images_val.shape[0], 1,48,48)\n",
    "  shape = (1,48,48)\n",
    "else:\n",
    "  images_train = images_train.reshape(images_train.shape[0], 48, 48, 1)\n",
    "  images_val = images_val.reshape(images_val.shape[0], 48, 48, 1)\n",
    "  shape = (48,48,1)\n",
    "print(K.image_data_format())\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e482d78d-1ff0-4bd0-865c-e9e20b2bd839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "641/641 [==============================] - 15s 23ms/step - loss: 3.0089 - accuracy: 0.2510 - val_loss: 1.0688 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "641/641 [==============================] - 15s 23ms/step - loss: 0.8781 - accuracy: 0.7285 - val_loss: 0.4680 - val_accuracy: 0.8438 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "641/641 [==============================] - 15s 23ms/step - loss: 0.4995 - accuracy: 0.8397 - val_loss: 0.3508 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "641/641 [==============================] - 15s 23ms/step - loss: 0.3605 - accuracy: 0.8849 - val_loss: 0.2014 - val_accuracy: 0.9341 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "641/641 [==============================] - 15s 23ms/step - loss: 0.2793 - accuracy: 0.9094 - val_loss: 0.2284 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.2290 - accuracy: 0.9251 - val_loss: 0.1813 - val_accuracy: 0.9436 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.2115 - accuracy: 0.9295 - val_loss: 0.1862 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.1770 - accuracy: 0.9416 - val_loss: 0.1646 - val_accuracy: 0.9483 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "641/641 [==============================] - 16s 24ms/step - loss: 0.1657 - accuracy: 0.9470 - val_loss: 0.1368 - val_accuracy: 0.9553 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "641/641 [==============================] - 15s 24ms/step - loss: 0.1419 - accuracy: 0.9545 - val_loss: 0.1158 - val_accuracy: 0.9639 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "641/641 [==============================] - 16s 24ms/step - loss: 0.1327 - accuracy: 0.9552 - val_loss: 0.1265 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.1219 - accuracy: 0.9589 - val_loss: 0.1253 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9618\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "641/641 [==============================] - 15s 24ms/step - loss: 0.1147 - accuracy: 0.9617 - val_loss: 0.1354 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "641/641 [==============================] - 15s 24ms/step - loss: 0.0717 - accuracy: 0.9746 - val_loss: 0.0822 - val_accuracy: 0.9768 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "641/641 [==============================] - 15s 23ms/step - loss: 0.0627 - accuracy: 0.9795 - val_loss: 0.0977 - val_accuracy: 0.9694 - lr: 5.0000e-04\n",
      "Epoch 16/30\n",
      "641/641 [==============================] - 15s 23ms/step - loss: 0.0539 - accuracy: 0.9817 - val_loss: 0.0973 - val_accuracy: 0.9731 - lr: 5.0000e-04\n",
      "Epoch 17/30\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9800\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "641/641 [==============================] - 15s 24ms/step - loss: 0.0593 - accuracy: 0.9800 - val_loss: 0.0891 - val_accuracy: 0.9731 - lr: 5.0000e-04\n",
      "Epoch 18/30\n",
      "641/641 [==============================] - 16s 24ms/step - loss: 0.0431 - accuracy: 0.9862 - val_loss: 0.0796 - val_accuracy: 0.9754 - lr: 2.5000e-04\n",
      "Epoch 19/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.0798 - val_accuracy: 0.9768 - lr: 2.5000e-04\n",
      "Epoch 20/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 0.0769 - val_accuracy: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 21/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.0366 - accuracy: 0.9872 - val_loss: 0.0711 - val_accuracy: 0.9774 - lr: 2.5000e-04\n",
      "Epoch 22/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 0.0808 - val_accuracy: 0.9774 - lr: 2.5000e-04\n",
      "Epoch 23/30\n",
      "641/641 [==============================] - 16s 24ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.0885 - val_accuracy: 0.9744 - lr: 2.5000e-04\n",
      "Epoch 24/30\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9894\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 0.0943 - val_accuracy: 0.9741 - lr: 2.5000e-04\n",
      "Epoch 25/30\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.0726 - val_accuracy: 0.9791 - lr: 1.2500e-04\n",
      "Epoch 26/30\n",
      "641/641 [==============================] - 16s 24ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0782 - val_accuracy: 0.9793 - lr: 1.2500e-04\n",
      "Epoch 27/30\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9932\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "641/641 [==============================] - 16s 25ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0740 - val_accuracy: 0.9778 - lr: 1.2500e-04\n",
      "Epoch 28/30\n",
      "641/641 [==============================] - 15s 24ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0716 - val_accuracy: 0.9791 - lr: 6.2500e-05\n",
      "Epoch 29/30\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9937Restoring model weights from the end of the best epoch: 21.\n",
      "641/641 [==============================] - 16s 24ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0779 - val_accuracy: 0.9780 - lr: 6.2500e-05\n",
      "Epoch 29: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yichen/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "# the model\n",
    "datagen = ImageDataGenerator(rotation_range=15,zoom_range=0.2)\n",
    "datagen.fit(images_train)\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Conv2D(16, (5,5), activation='relu', input_shape=shape),\n",
    "  keras.layers.MaxPooling2D(2,2),\n",
    "  keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(2,2),\n",
    "  keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(2,2),\n",
    "  keras.layers.Flatten(),\n",
    "  # keras.layers.Dropout(0.5),\n",
    "  keras.layers.Dense(512, activation='relu'),\n",
    "  keras.layers.Dense(71, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "model.fit(datagen.flow(images_train,labels_train,shuffle=True),epochs=30,batch_size=16,\\\n",
    "                    validation_data=(images_val,labels_val), \\\n",
    "                    callbacks = [keras.callbacks.EarlyStopping(patience=8,verbose=1,restore_best_weights=True), \\\n",
    "                                 keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=3,verbose=1)])\n",
    "tensorboard= TensorBoard(log_dir=\"logs\")\n",
    "model.save(\"hiragana-model.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9c7b7-7c7c-4bcb-9847-f6fff3a3c5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
